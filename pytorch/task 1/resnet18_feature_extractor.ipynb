{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2YyqCX1fa1nd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import glob\n",
        "import yaml\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_files():\n",
        "    import google.colab\n",
        "    import zipfile\n",
        "\n",
        "    google.colab.drive.mount('/content/drive')\n",
        "    PROJECT_DIR = \"/content/drive/MyDrive/thesis/data/\"\n",
        "\n",
        "    zip_ref = zipfile.ZipFile(PROJECT_DIR + \"fiveK.zip\", 'r')\n",
        "    zip_ref.extractall(\".\")\n",
        "    zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  extract_files()\n",
        "  config_path = \"/content/drive/MyDrive/thesis/config.yaml\"\n",
        "else:\n",
        "  config_path = \"../../config.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class directories\n",
        "class_directories = ['expA', 'expB', 'expC', 'expD', 'expE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, filename, transform=None):\n",
        "        super().__init__()\n",
        "        self.filename = filename\n",
        "        self.transform = transform\n",
        "        self.classname = self._extract_class_name(data_dir)\n",
        "        self.encode = {k: i for i, k in enumerate(class_directories)}\n",
        "\n",
        "        # Read the train.txt file and store the image paths\n",
        "        with open(self.filename) as f:\n",
        "            self.image_paths = [os.path.join(data_dir, line.strip()) for line in f]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        image = Image.open(image_path)\n",
        "        label = self.encode[self.classname]\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def _extract_class_name(self, root_dir):\n",
        "        # Extract the class name from the root directory\n",
        "        class_name = os.path.basename(root_dir)\n",
        "        return class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    # Load configuration\n",
        "    with open(config_path, 'r') as config_file:\n",
        "        config = yaml.safe_load(config_file)\n",
        "except:\n",
        "    raise FileNotFoundError(f\"Config file not found at path: {config_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_folder = config['paths']['data']\n",
        "train_file = config['paths']['train']\n",
        "test_file = config['paths']['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_dataset(data_folder, txt_file, trasform=None):\n",
        "    # Create separate datasets for each class\n",
        "    datasets = []\n",
        "\n",
        "    for class_dir in class_directories:\n",
        "        class_train_dataset = CustomDataset(\n",
        "            data_dir=os.path.join(data_folder, class_dir),\n",
        "            filename=os.path.join(txt_file),\n",
        "            transform=trasform\n",
        "        )\n",
        "        datasets.append(class_train_dataset)\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_tr = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "test_tr = transforms.Compose([\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine datasets if needed (e.g., for training)\n",
        "train_dataset = torch.utils.data.ConcatDataset(read_dataset(data_folder, train_file, training_tr))\n",
        "test_dataset = torch.utils.data.ConcatDataset(read_dataset(data_folder, test_file, test_tr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bs = 256\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=bs*2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unique_classes = set(class_label for _, class_label in train_dataset)\n",
        "\n",
        "# # Print the unique classes\n",
        "# print(\"All Classes:\", unique_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Display image for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of training data\n",
        "inputs, labels = next(iter(train_dataloader))\n",
        "# Make a grid from first 2 images in the batch\n",
        "out = torchvision.utils.make_grid(inputs[:2])\n",
        "imshow(out, title=[class_directories[x] for x in labels[:2]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/42703500/how-do-i-save-a-trained-model-in-pytorch\n",
        "# how to save the model\n",
        "# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html#:~:text=Load%20the%20general%20checkpoint,-Remember%20to%20first&text=eval()%20to%20set%20dropout,layers%20are%20in%20training%20mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_checkpoint_path = os.path.join(config['paths']['checkpoints'], 'resetnet18_feature_extractor')\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "if not os.path.exists(base_checkpoint_path):\n",
        "    os.makedirs(base_checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, current_epoch, num_epochs=25):\n",
        "    since = time.time()\n",
        "    best_acc = 0.0\n",
        "    model.train()\n",
        "    for epoch in range(current_epoch, num_epochs):\n",
        "            # formatted string to append epoch number to checkpoint filename\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "\n",
        "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        print()\n",
        "\n",
        "        PATH = os.path.join(base_checkpoint_path, f'resetnet18_feature_extractor_{epoch+1}.pth')\n",
        "        # save checkpoint\n",
        "        state = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': epoch_loss,\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'accuracy': epoch_acc\n",
        "        }\n",
        "        # save the best model parameters\n",
        "        torch.save(state, PATH)\n",
        "        # deep copy the model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
        "# Freeze all layers except the fully connected layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "# move the model to GPU/CPU\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the last model saved if there is any\n",
        "def load_latest_model(model, optimizer, scheduler, checkpoint_dir):\n",
        "    # Check if the directory exists\n",
        "    if not os.path.exists(base_checkpoint_path):\n",
        "        print(f\"No directory found: {checkpoint_dir}\")\n",
        "        return model, optimizer, scheduler, 0, None\n",
        "\n",
        "    # Get a list of all checkpoint files in the directory\n",
        "    checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'resetnet18_feature_extractor_*.pth'))\n",
        "\n",
        "    # Check if any checkpoint files are present\n",
        "    if not checkpoint_files:\n",
        "        print(f\"No checkpoints found in the directory: {checkpoint_dir}\")\n",
        "        return model, optimizer, scheduler, 0, None\n",
        "\n",
        "    # Find the latest checkpoint file based on the epoch number in the filename\n",
        "    latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n",
        "\n",
        "    # Load the latest checkpoint\n",
        "    checkpoint = torch.load(latest_checkpoint, map_location=torch.device(device))\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "\n",
        "    print(f\"Loaded model from checkpoint: {latest_checkpoint}\")\n",
        "    print(f\"Resuming training from epoch {epoch}\")\n",
        "\n",
        "    return model, optimizer,scheduler, epoch, loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, optimizer, scheduler, current_epoch, loss = load_latest_model(model, optimizer, scheduler, base_checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSyJd04Wa1nq",
        "outputId": "897a62e3-655c-4819-916b-5ff7f80fe783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50\n",
            "----------\n",
            "Loss: 1.7334 Acc: 0.1981\n",
            "\n",
            "Epoch 5/50\n",
            "----------\n",
            "Loss: 1.7324 Acc: 0.1972\n",
            "\n",
            "Epoch 6/50\n",
            "----------\n",
            "Loss: 1.7322 Acc: 0.1961\n",
            "\n",
            "Epoch 7/50\n",
            "----------\n",
            "Loss: 1.7342 Acc: 0.1912\n",
            "\n",
            "Epoch 8/50\n",
            "----------\n",
            "Loss: 1.7318 Acc: 0.1987\n",
            "\n",
            "Epoch 9/50\n",
            "----------\n",
            "Loss: 1.7309 Acc: 0.1971\n",
            "\n",
            "Epoch 10/50\n",
            "----------\n",
            "Loss: 1.7318 Acc: 0.1958\n",
            "\n",
            "Epoch 11/50\n",
            "----------\n",
            "Loss: 1.7328 Acc: 0.1967\n",
            "\n",
            "Epoch 12/50\n",
            "----------\n",
            "Loss: 1.7316 Acc: 0.1980\n",
            "\n",
            "Epoch 13/50\n",
            "----------\n",
            "Loss: 1.7299 Acc: 0.1975\n",
            "\n",
            "Epoch 14/50\n",
            "----------\n",
            "Loss: 1.7314 Acc: 0.1961\n",
            "\n",
            "Epoch 15/50\n",
            "----------\n",
            "Loss: 1.7298 Acc: 0.1981\n",
            "\n",
            "Epoch 16/50\n",
            "----------\n",
            "Loss: 1.7338 Acc: 0.1962\n",
            "\n",
            "Epoch 17/50\n",
            "----------\n",
            "Loss: 1.7332 Acc: 0.1977\n",
            "\n",
            "Epoch 18/50\n",
            "----------\n",
            "Loss: 1.7324 Acc: 0.1954\n",
            "\n",
            "Epoch 19/50\n",
            "----------\n",
            "Loss: 1.7353 Acc: 0.1962\n",
            "\n",
            "Epoch 20/50\n",
            "----------\n",
            "Loss: 1.7339 Acc: 0.1958\n",
            "\n",
            "Epoch 21/50\n",
            "----------\n",
            "Loss: 1.7302 Acc: 0.1987\n",
            "\n",
            "Epoch 22/50\n",
            "----------\n",
            "Loss: 1.7345 Acc: 0.1960\n",
            "\n",
            "Epoch 23/50\n",
            "----------\n",
            "Loss: 1.7319 Acc: 0.1985\n",
            "\n",
            "Epoch 24/50\n",
            "----------\n",
            "Loss: 1.7298 Acc: 0.1995\n",
            "\n",
            "Epoch 25/50\n",
            "----------\n",
            "Loss: 1.7293 Acc: 0.1990\n",
            "\n",
            "Epoch 26/50\n",
            "----------\n",
            "Loss: 1.7334 Acc: 0.1972\n",
            "\n",
            "Epoch 27/50\n",
            "----------\n",
            "Loss: 1.7335 Acc: 0.1918\n",
            "\n",
            "Epoch 28/50\n",
            "----------\n",
            "Loss: 1.7328 Acc: 0.1958\n",
            "\n",
            "Epoch 29/50\n",
            "----------\n",
            "Loss: 1.7342 Acc: 0.1985\n",
            "\n",
            "Epoch 30/50\n",
            "----------\n",
            "Loss: 1.7311 Acc: 0.1985\n",
            "\n",
            "Epoch 31/50\n",
            "----------\n",
            "Loss: 1.7314 Acc: 0.1958\n",
            "\n",
            "Epoch 32/50\n",
            "----------\n",
            "Loss: 1.7324 Acc: 0.1981\n",
            "\n",
            "Epoch 33/50\n",
            "----------\n",
            "Loss: 1.7320 Acc: 0.1973\n",
            "\n",
            "Epoch 34/50\n",
            "----------\n",
            "Loss: 1.7339 Acc: 0.1973\n",
            "\n",
            "Epoch 35/50\n",
            "----------\n",
            "Loss: 1.7327 Acc: 0.1957\n",
            "\n",
            "Epoch 36/50\n",
            "----------\n",
            "Loss: 1.7308 Acc: 0.1984\n",
            "\n",
            "Epoch 37/50\n",
            "----------\n",
            "Loss: 1.7324 Acc: 0.1963\n",
            "\n",
            "Epoch 38/50\n",
            "----------\n",
            "Loss: 1.7319 Acc: 0.1958\n",
            "\n",
            "Epoch 39/50\n",
            "----------\n",
            "Loss: 1.7312 Acc: 0.1976\n",
            "\n",
            "Epoch 40/50\n",
            "----------\n",
            "Loss: 1.7332 Acc: 0.1986\n",
            "\n",
            "Epoch 41/50\n",
            "----------\n",
            "Loss: 1.7312 Acc: 0.1995\n",
            "\n",
            "Epoch 42/50\n",
            "----------\n",
            "Loss: 1.7350 Acc: 0.1983\n",
            "\n",
            "Epoch 43/50\n",
            "----------\n",
            "Loss: 1.7307 Acc: 0.1940\n",
            "\n",
            "Epoch 44/50\n",
            "----------\n",
            "Loss: 1.7346 Acc: 0.1975\n",
            "\n",
            "Epoch 45/50\n",
            "----------\n",
            "Loss: 1.7300 Acc: 0.1964\n",
            "\n",
            "Epoch 46/50\n",
            "----------\n",
            "Loss: 1.7296 Acc: 0.1990\n",
            "\n",
            "Epoch 47/50\n",
            "----------\n",
            "Loss: 1.7312 Acc: 0.1975\n",
            "\n",
            "Epoch 48/50\n",
            "----------\n",
            "Loss: 1.7306 Acc: 0.1958\n",
            "\n",
            "Epoch 49/50\n",
            "----------\n",
            "Loss: 1.7335 Acc: 0.1962\n",
            "\n",
            "Epoch 50/50\n",
            "----------\n",
            "Loss: 1.7339 Acc: 0.1960\n",
            "\n",
            "Training complete in 84m 19s\n",
            "Best val Acc: 0.199500\n"
          ]
        }
      ],
      "source": [
        "train_model(model, criterion, optimizer, scheduler,current_epoch, num_epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NSjARUuIa1nq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
